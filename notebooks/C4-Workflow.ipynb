{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760a01f9-84aa-45cf-a023-c990daf0cf59",
   "metadata": {},
   "source": [
    "# Model Deployment Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5da0c2-b5fe-45ad-86a8-d6301cb12a5e",
   "metadata": {},
   "source": [
    "<img src=\"../assets/workflow.svg\" alt=\"Workflow\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06b378-8136-4bb2-9e23-53e4d8b4cbf6",
   "metadata": {},
   "source": [
    "1. **Data Splitting**\n",
    "   - Isolate changes in data preparation.\n",
    "   - Prevent issues (bias) with whole dataset processing.\n",
    "\n",
    "\n",
    "2. **Data Preparation**\n",
    "   - Data needs to be in a format the model can use for training.\n",
    "   - Most data is dirty.\n",
    "   - Some data may be processed by the EDA step.\n",
    "\n",
    "\n",
    "3. **Training**\n",
    "   - Model training works best with clean data.\n",
    "\n",
    "\n",
    "4. **Evaluation**\n",
    "   - Evaluate model on unseen data.\n",
    "   - Outcome leads to product decisions.\n",
    "\n",
    "\n",
    "5. **Tuning**\n",
    "   - Change how model is trained based on feedback from previous step.\n",
    "   - The whole workflow is a code, allowing for repeatable iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef57eb-3682-41ea-8b24-d904a5e89810",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d0e1a-e17c-4c3f-85ec-1486c99f3d93",
   "metadata": {},
   "source": [
    "## Workflow Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55f260-dc54-46e7-9b3c-5f80f21994e5",
   "metadata": {},
   "source": [
    "1. **Bad Data**: \"Garbage in, garbage out\". If the data is bad before training\n",
    "the model, it won't perform well.\n",
    "\n",
    "2. **Unrepeatable Results**: When the workflow is structured in a repeatable\n",
    "way, it'll prevent errors, such as any surprise when moving the work to final\n",
    "stages of production.\n",
    "\n",
    "3. **Not Enough Resources**: Having a workflow provides a way to see how the\n",
    "model reacts to different resources. It's possible to run on better machines,\n",
    "reducing the time it tales to complete. It's also possible to calculate the\n",
    "costs from the workflows when iterating, providin better estimates of product\n",
    "timeline.\n",
    "\n",
    "4. **Model Complexity**: Having a workflow allows for a better undestanding of\n",
    "the entire process in a transparent way. If there's a bad metric or\n",
    "miscalculation, it's possible to quickly change what needs to be done in order\n",
    "for the workflow to be rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9654617-bac5-4adb-983a-de2ab197a166",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaed6ee-90bb-44b0-bfe6-d3056dba0780",
   "metadata": {},
   "source": [
    "## Dataset Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef152f-8935-4d36-b64f-00c08baab235",
   "metadata": {},
   "source": [
    "1. **Feature Values** are columnar data for a row.\n",
    "   - Used by models to predict the target value.\n",
    "   - Can be described as the attributes of a given data point.\n",
    "\n",
    "\n",
    "2. **Target Value** is a selected column to be predicted by the model.\n",
    "   - In reality, any feature could be a target value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44823e-9575-4d27-b50d-2b09a0459772",
   "metadata": {},
   "source": [
    "> Training a model on the entire dataset and then testing it on the same\n",
    "dataset, allows the model to memorize what the data looks like. In order to\n",
    "have a true idea of its performance, we need to test it on unseen data.\n",
    "Datasets are then split before training to prevent **overfitting** the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816b2bf-b9f4-4332-8a8b-51256c09a11b",
   "metadata": {},
   "source": [
    "There are two methods to split the data:\n",
    "\n",
    "1. Split the data in **train** and **test**. Train the model on the training\n",
    "dataset and test and tune the model on the **test** dataset.\n",
    "\n",
    "2. Split the data in **train**, **validation**, and **test**. Train the model\n",
    "on the training dataset, tune the model on the **validation** dataset, and\n",
    "finally test your model on the **test** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a24fc4-a353-4702-b153-668f0f6b9912",
   "metadata": {},
   "source": [
    "### Example / Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e211b-0c01-4b3f-a19d-b73d6e97e96e",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.DataFrame([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998a688-998b-46f9-a340-7f9cc8daf0ee",
   "metadata": {},
   "source": [
    "- `test_size=0.2` send 20% to the test dataset.\n",
    "- `random_state=0` makes the splitting repeatable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c4c3b-80a4-4281-9633-b2827e48909b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e623b4-f697-42f3-90bb-851f882bdba6",
   "metadata": {},
   "source": [
    "> There's an article about `train_test_split` in Real Python's website,\n",
    "[here](https://realpython.com/train-test-split-python-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1496ac8-ba2b-46fb-bed5-46a9dc98063c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbfdac-3599-4cd8-9948-c32e338dfb6f",
   "metadata": {},
   "source": [
    "## Data Cleansing\n",
    "\n",
    "- Bad data could be **missing** or **wrong**.\n",
    "- **Remove** missing or invalid data.\n",
    "- Remove entre rows or columns if dats is missing.\n",
    "- Possible fix bad values by **replacing with average or interpolation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339b7b7-36c2-43f6-8bad-e1257347a1b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3faf21-ac8d-4b9b-822c-b944a7796975",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09c4ee-0fab-4063-8bf7-b8b4117297f8",
   "metadata": {},
   "source": [
    "Modify or extend the current features in a datset with additional insights or\n",
    "data, increasing the effectiveness of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d138e8d-4d65-44b3-9f15-55459437f524",
   "metadata": {},
   "source": [
    "1. **Changing Data Types** can be done with `astype()`.\n",
    "\n",
    "2. **Normalizing Data**, by transforming numerical data to have specific range\n",
    "of values, typically having zero mean, with Scikit Learn's `StandardScaler`.\n",
    "\n",
    "3. **Parsing Data Types**, such as datetime strings with `to_datetime()`.\n",
    "\n",
    "4. **One-Hot Encoding**, i.e. convert categorical data to feature columns with\n",
    "`get_dummies()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec732dbc-6fb8-48ab-862f-609b8ef6ab36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59409650-de97-4319-8fbc-18c4ee73329d",
   "metadata": {},
   "source": [
    "> There's an article on Real Python about data cleansing,\n",
    "[here](https://realpython.com/python-data-cleaning-numpy-pandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bb99f-4d13-43d9-8865-03ebe2559bff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb82dd-c854-488b-b264-de71d32e9299",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75f5f0-d369-4f20-8b0c-389f9d10ca1a",
   "metadata": {},
   "source": [
    "- Training is resource intensive (memory, CPU, GPU).\n",
    "- Datasets can have hundreds of GBs.\n",
    "- Sample dataseta, batch processing and distributed training are ways to reduce the size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5d7c4-5fb6-4bff-882a-2acd27153808",
   "metadata": {},
   "source": [
    "Scikit-Learn's API is standardized across all algorithms:\n",
    "\n",
    "- `fit()` trains the model.\n",
    "- `score()` evaluates metrics.\n",
    "- `predict()` is used to predict new target values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340f524-356f-4ab4-a9b3-03f6fec5ba19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceef2f3-df25-489d-8700-c2aefce39f48",
   "metadata": {},
   "source": [
    "## Metrics Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620118f-65c9-42f8-be47-86dc46e7192f",
   "metadata": {},
   "source": [
    "1. **Regression metrics** compare the predicted output with real output values,\n",
    "and their difference determines the model performance.\n",
    "   - **R2** measures the proportion of variance and is related to correlation,\n",
    "   ranging from `-1` to `1` (the higher the better).\n",
    "   - **Root mean square error (RMSE)** measures the standard deviation of\n",
    "   prediction errors. The lower the better.\n",
    "\n",
    "\n",
    "2. **Classification metrics** compare the predicted label with real label.\n",
    "   - $Accuracy = \\frac{TP + TN}{Total}$\n",
    "\n",
    "   - $Precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "   - $Recall = \\frac{TP}{TP + FN}$\n",
    "   \n",
    "   - $F1$ is the harmonic mean between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddbb2e-83f2-4001-bee1-c28f24b81f65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c6140-234d-42df-98b1-6a203320f7a5",
   "metadata": {},
   "source": [
    "> A list of metrics available can be found\n",
    "[here](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106810b-dd38-4b72-8243-c8891a0922fa",
   "metadata": {},
   "source": [
    "> There's a blog post on Medium about popular metrics,\n",
    "[here](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a06877-48ca-46e7-9a6a-8d75501de783",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda6244-7970-495c-bb27-0aae85a55623",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8037750-2901-4045-93d1-4f333dfe9def",
   "metadata": {},
   "source": [
    "- Change model's configurations, therefore increase/decrease its perfomance.\n",
    "- Recommended to start with the default.\n",
    "- There are numerous methods for searching the optimized combination (Grid\n",
    "search, Randomized search, Bayesian search...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc155a0-ceeb-4275-b425-35ae81aa6659",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc9152-6250-4442-ac75-cec8f85d8e3d",
   "metadata": {},
   "source": [
    "> There's a blog post from Neptune about hyperparameter search, available\n",
    "[here](https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72312f4-18a8-4788-a01a-c595c83d0a76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da8e6e-cbb5-4b66-81c4-e483e79e8bfe",
   "metadata": {},
   "source": [
    "## Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbe2d2-8452-4967-83a0-1ff193c84d34",
   "metadata": {},
   "source": [
    "- Small datasets may not work with train/validation/test data splitting.\n",
    "- If a dataset is already cleaned and processed, there's no point in doing it\n",
    "again.\n",
    "- Avoid metrics with unknown relation to the data.\n",
    "- If default hyperparameters work well, doing a hyperparameter search may not\n",
    "be worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82545a4-8a1e-49e2-9bca-0dd8b3f63a86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf682f7-17a5-4b40-9e21-498adb7a79f5",
   "metadata": {},
   "source": [
    "> MLOps is another name for model deployment, and there is an article about it\n",
    "[here](https://ml-ops.org/content/end-to-end-ml-workflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7683f13-901c-4608-9188-84aa116b3555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42467c3a-d308-45fc-8559-2bb2c41a2109",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ff88a-b007-4879-bc31-3ce872b67766",
   "metadata": {},
   "source": [
    "08. **Dataset Principles**: This basic lesson's goal was to introduce the\n",
    "    concept of splitting the dataset into three parts: training, validation,\n",
    "    and test.\n",
    "\n",
    "09. **Data Cleansing and Feature Engineering**: Having learned about data\n",
    "    splitting, this exercise provides a hands-on experience cleaning and\n",
    "    processing it.\n",
    "\n",
    "10. **Model Training and Evaluation**: After finishing working on the dataset,\n",
    "    we learn about training the model with this practical exercise. Also, after\n",
    "    training, we evalute the model's performance calculating its score.\n",
    "\n",
    "11. **Diabetes Model**: This final lesson, wraps up using everything: splitting\n",
    "    the dataset (no cleaning and processing, since it's already done), creating\n",
    "    and training a model, tuning the hyperparameters, and finally calculating\n",
    "    the score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
