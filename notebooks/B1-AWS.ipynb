{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618c64d2-7b92-4d9f-9d34-e0a9a2788601",
   "metadata": {},
   "source": [
    "# AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4c41c-1011-461b-8b3c-0798c4095411",
   "metadata": {},
   "source": [
    "Amazon Web Services provides lots of services for cloud computing, including Machine Learning. Some ML services are under the AWS SageMaker umbrella:\n",
    "\n",
    "- SageMaker Studio\n",
    "  - Data Wrangler\n",
    "  - Processing\n",
    "  - Feature Store\n",
    "  - Clarify\n",
    "  - ...\n",
    "- Ground Truth\n",
    "- Inference\n",
    "- ...\n",
    "\n",
    "The main part here is the SageMaker Studio, which is a cloud-based IDE, centered around Jupyter Lab.\n",
    "\n",
    "> AWS SageMaker has tons of features, which can be found [here](https://aws.amazon.com/sagemaker/features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66e35a-f7a0-4759-8181-e66b17256263",
   "metadata": {},
   "source": [
    "## SageMaker Studio\n",
    "\n",
    "> Amazon SageMaker helps data scientists and developers to prepare, build,\n",
    "train, and deploy high-quality machine learning models quickly by bringing\n",
    "together a broad set of capabilities purpose-built for machine learning.\n",
    "-- [AWS][1]\n",
    "\n",
    "[1]: https://aws.amazon.com/pm/sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9910e-48f5-4a26-a64a-c7bac5a0bb1a",
   "metadata": {},
   "source": [
    "Its key features are:\n",
    "\n",
    "- File explorer: Upload and download files\n",
    "- Git repository: Clone git repositories straight into SageMaker Studio\n",
    "- Notebooks: Create notebooks with data science provided kernels\n",
    "- EC2 instance: Configure an instance to run notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53989372-696f-49fe-9b8f-701f73cebb32",
   "metadata": {},
   "source": [
    "## Data Wrangler\n",
    "\n",
    "> Amazon SageMaker Data Wrangler reduces the time it takes to aggregate and\n",
    "prepare data for machine learning (ML) from weeks to minutes. With SageMaker\n",
    "Data Wrangler, you can simplify the process of data preparation and feature\n",
    "engineering, and complete each step of the data preparation workflow, including\n",
    "data selection, cleansing, exploration, and visualization from a single visual\n",
    "interface. Using SageMaker Data Wrangler’s data selection tool, you can choose\n",
    "the data you want from various data sources and import it with a single click.\n",
    "SageMaker Data Wrangler contains over 300 built-in data transformations so you\n",
    "can quickly normalize, transform, and combine features without having to write\n",
    "any code. With SageMaker Data Wrangler’s visualization templates, you can\n",
    "quickly preview and inspect that these transformations are completed as you\n",
    "intended by viewing them in Amazon SageMaker Studio, the first fully integrated\n",
    "development environment (IDE) for ML. Once your data is prepared, you can build\n",
    "fully automated ML workflows with Amazon SageMaker Pipelines and save them for\n",
    "reuse in the Amazon SageMaker Feature Store. -- [AWS][1]\n",
    "\n",
    "[1]: https://aws.amazon.com/sagemaker/data-wrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772e98b-3011-4cca-911e-f219558e38bc",
   "metadata": {},
   "source": [
    "Creating an ETL pipeline with Data Wrangler is very easy and intuitive. When in\n",
    "the Data Wranger page, the first thing to do is import the data, which can be\n",
    "done from S3 or Athena. To do some transformation, click the plus sign in the\n",
    "diagram, which will prompt what transformation should be done. After choosing\n",
    "one on the right side, it's possible to preview and add. To create an analysis,\n",
    "just follow the same path, i.e. click on the plus sign, choose an analysis on\n",
    "the right side and apply. To export, go to the export tab, click the last step\n",
    "on the diagram and choose to export. Selecting the S3 option will open a\n",
    "notebook. Run each cell to prepare and export the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e73277-c04d-43a6-8b73-500fb7325b1e",
   "metadata": {},
   "source": [
    "## S3\n",
    "\n",
    "> Amazon Simple Storage Service (Amazon S3) is an object storage service\n",
    "offering industry-leading scalability, data availability, security, and\n",
    "performance. Customers of all sizes and industries can store and protect any\n",
    "amount of data for virtually any use case, such as data lakes, cloud-native\n",
    "applications, and mobile apps. With cost-effective storage classes and\n",
    "easy-to-use management features, you can optimize costs, organize data, and\n",
    "configure fine-tuned access controls to meet specific business, organizational,\n",
    "and compliance requirements. -- [AWS][1]\n",
    "\n",
    "[1]: https://aws.amazon.com/s3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
