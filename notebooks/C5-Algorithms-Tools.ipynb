{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f8835e-9a8e-4961-b543-67af34b9adce",
   "metadata": {},
   "source": [
    "# Algorithms & Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed615af8-16c9-466b-8665-96a9ef2745ca",
   "metadata": {},
   "source": [
    "> Data is more important than tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b1d9a-7c18-44d8-a5a1-6fe08c6bdb6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ba83b-a35d-4afc-b54b-d25f8820efa6",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ed80f-de7c-443f-9c9f-08c6efb2aecd",
   "metadata": {},
   "source": [
    "- Classification or regression.\n",
    "- Easy to interpret, train, and deploy.\n",
    "- Typically first to explore, but not as powerful as other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c133311-824e-47b1-b710-e583c14660c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5cbc83-8cda-4464-aebf-e762fdf8df18",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfda9bf-f17c-40c2-9092-de6c86bdfb87",
   "metadata": {},
   "source": [
    "- Classification or regression.\n",
    "- Easy to visualize.\n",
    "- Nodes are decision points, branches are the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36707c-ac5c-4000-a2e4-65ed857d7a6f",
   "metadata": {},
   "source": [
    "- **Random Forests** are an ensemble model, composed of multiple trees, then\n",
    "summarized.\n",
    "\n",
    "- **Hierarquical Clustering** is a tree-based model, but not a supervised\n",
    "model.\n",
    "\n",
    "- **Feature Selection** is done, since top nodes are more important, and best\n",
    "split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74232e85-f213-46f6-a22d-3a81c43cdeca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66717a5a-7418-4133-b951-4ff642fd0463",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2afbdd-13d9-4e63-9b45-a0ee4bbae053",
   "metadata": {},
   "source": [
    "- Tree-based model, comprised of weak-learners.\n",
    "- Usually outperforms random forest.\n",
    "- Highly tunable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a251b-4141-4f55-b9a1-5380970f155d",
   "metadata": {},
   "source": [
    "### Example / Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b67a1-5236-4b5b-9447-96ba9bb9ca0b",
   "metadata": {},
   "source": [
    "1. Import Pandas and XGBoost\n",
    "2. Create DataFrame\n",
    "3. Create Data Matrix\n",
    "4. Train the model\n",
    "5. Predict target values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ba235-e83a-4004-810b-4a89ffb4a826",
   "metadata": {},
   "source": [
    "```python\n",
    "# [1] Import Pandas and XGBoost\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# [2] Create DataFrame\n",
    "df = pd.DataFrame([[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]], columns=[\"num\", \"amount\", \"target\"])\n",
    "\n",
    "# [3] Create Data Matrix\n",
    "df_xgb = xgb.DMatrix(df[[\"num\", \"amount\"]], label=df[\"target\"])\n",
    "\n",
    "# [4] Train the model\n",
    "params = {\"eval_metric\": \"logloss\", \"objective\": \"binary:hinge\"}\n",
    "bst = xgb.train(params, df_xgb)\n",
    "\n",
    "# [5] Predict target values\n",
    "bst.predict(df_xgb)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93ccd8-5278-4741-affe-650cf9905dbc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a38c2b-f739-49e9-b438-893424c65d65",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5fb19-12ff-44ca-b5be-7c4dc778ab66",
   "metadata": {},
   "source": [
    "- Framework to automate processing, creation, and tuning of ML models.\n",
    "- Define target feature and duration of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56c3d7-fb0a-4e22-9e7e-6b85200e27a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349c4d5-3c1c-42af-928f-746f23d16514",
   "metadata": {},
   "source": [
    "> AutoGluon is part of the AutoML class of models, which automates ML workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d134b-0e70-4f7a-b94d-7c479a052cd9",
   "metadata": {},
   "source": [
    "> More AutoML stuff can be found on Awesome's curated list,\n",
    "[here](https://github.com/windmaple/awesome-AutoML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10cb10-5060-4d12-8e7f-4fad453b6572",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c9ce6-feb9-4480-8501-6f0ed5019995",
   "metadata": {},
   "source": [
    "### Example / Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a014a-c253-4665-b3a5-95541007483a",
   "metadata": {},
   "source": [
    "1. Import Pandas and AutoGluon's `TabularPredictor`.\n",
    "2. Create `DataFrame`.\n",
    "3. Create `TabularPredictor`, passing data, time limit and objective.\n",
    "4. Check summary of created models.\n",
    "5. Evaluate best model's hyperparameters search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba0529-f1d2-483e-b97b-d2f47af5a863",
   "metadata": {},
   "source": [
    "```python\n",
    "# [1] Import Pandas and AutoGluon's TabularPredictor\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# [2] Create DataFrame\n",
    "df = pd.DataFrame([[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]],\n",
    "                  columns=[\"num\", \"amount\", \"target\"])\n",
    "\n",
    "# [3] Create TabularPredictor, passing data, time limit and objective.\n",
    "predictor = TabularPredictor(label=\"target\") \\\n",
    "    .fit(train_data=df, time_limit=60, presets=\"best_quality\")\n",
    "\n",
    "# [4] Check summary of created models\n",
    "predictor.fit_summary()\n",
    "\n",
    "# [5] Evaluate best model's hyperparameters search\n",
    "predictor.evaluate(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afdf18-8c95-4125-8579-3ef6b9b4bbdf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b4c2d-004b-4695-a328-675f161e2757",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76552f17-e965-459e-9c00-2ee0255527d7",
   "metadata": {},
   "source": [
    "12. **Linear Models**: This first exercise explores two linear models, a\n",
    "    classification and a regression.\n",
    "\n",
    "13. **XGBoost**: After learning a little about linear models, random forests,\n",
    "    this lesson puts XGBoost to practice, showing how to use its API to train,\n",
    "    and test a model.\n",
    "\n",
    "14. **AutoGluon**: To finish this part of the course, we use AutoGluon to train\n",
    "    multiple models easily, both for classification and regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
