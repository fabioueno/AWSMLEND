{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9520883-fb9c-42fd-8d73-d19e3a401c7f",
   "metadata": {},
   "source": [
    "Throughout this lesson, you've been trying different models on the same two\n",
    "datasets, wine and diabetes. Now, we're going to try our hand at accelerating\n",
    "this methodology by using AutoGluon. In this exercise, train two different\n",
    "AutonGluon models and see how they compare to previous iterations in exercise 1\n",
    "and 2.\n",
    "\n",
    "You're tasked with completing the following steps:\n",
    "\n",
    "1. Load in the wine dataset from Scikit Learn.\n",
    "2. For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "3. Create an AutoGluon Classifier model with these hyper parameters:\n",
    "    1. `time_limit`: `120`\n",
    "    2. `presets`: `best_quality`\n",
    "4. Output the model table summary.\n",
    "5. Evaluate the trained model on the test dataset.\n",
    "6. Load the diabetes dataset from Scikit Learn.\n",
    "7. For the diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "8. Create an AutoGluon Regression model with these hyper parameters:\n",
    "    1. `eval_metric`: `r2`\n",
    "    2. `time_limit`: `120`\n",
    "    3. `presets`: `best_quality`\n",
    "9. Output the model table summary.\n",
    "10. Evaluate the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0ac658-af67-4355-a789-147a1a98b7cd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc846de2-0e72-4935-a786-ae65df4f2948",
   "metadata": {},
   "source": [
    "### Open up Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cbe42-87c5-4671-87e4-507764ad0ed4",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernel: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158af04-dd1d-4e26-8e63-e81de4e6bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfefd6d-ed7f-46e3-a0c0-befda8d6aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6fd8c-df16-4109-a7a8-6c6ccb2cdf29",
   "metadata": {},
   "source": [
    "## AutoGluon Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9c70a0-c311-4cf7-befb-92641f071326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d674674-0c0f-4a2a-8d0a-c8b1fc4c11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wine `data` dataset as a dataframe and name the columns with\n",
    "# `feature_names`\n",
    "df = pd.DataFrame(wine[\"data\"], columns=wine[\"feature_names\"])\n",
    "\n",
    "# Include the target as well\n",
    "df[\"target\"] = wine[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ee9c82-4e05-4952-8be9-7f823436d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7205ac08-20cd-48c5-a90e-44960f6d81f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220110_214459/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220110_214459/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    142\n",
      "Train Data Columns: 13\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [2, 1, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2620.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.83s of the 119.78s of remaining time.\n",
      "\t0.662\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.73s of the 119.67s of remaining time.\n",
      "\t0.7113\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 119.67s of the 119.62s of remaining time.\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t8.64s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 110.69s of the 110.63s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: image not found\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 109.66s of the 109.6s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: image not found\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 109.59s of the 109.54s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 108.64s of the 108.59s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 107.76s of the 107.71s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 105.62s of the 105.57s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 104.74s of the 104.68s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 103.96s of the 103.91s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 102.03s of the 101.98s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t9.23s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 92.09s of the 92.03s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: image not found\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 92.04s of the 91.98s of remaining time.\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t13.18s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 87.32s of the 87.26s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 86.14s of the 86.08s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 84.17s of the 84.12s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t18.42s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 74.24s of the 74.19s of remaining time.\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t17.56s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 69.66s of the 69.6s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t5.26s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 67.58s of the 67.53s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t5.16s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 65.61s of the 65.55s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t27.25s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 55.79s of the 55.73s of remaining time.\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t22.47s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 50.68s of the 50.63s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 48.99s of the 48.94s of remaining time.\n",
      "\t0.9648\t = Validation score   (accuracy)\n",
      "\t6.89s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 47.04s of the 46.98s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t36.6s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Repeating k-fold bagging: 5/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 37.02s of the 36.97s of remaining time.\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t27.12s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 32.19s of the 32.13s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t8.55s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 30.49s of the 30.44s of remaining time.\n",
      "\t0.9577\t = Validation score   (accuracy)\n",
      "\t8.57s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 28.58s of the 28.53s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t47.39s\t = Training   runtime\n",
      "\t2.96s\t = Validation runtime\n",
      "Completed 5/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.83s of the 17.01s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 103.31s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220110_214459/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model\n",
    "# parameters? Using the hyperparameters in the requirements, is there\n",
    "# improvement? Remember we use the test dataset to score the model. No need to\n",
    "# explicitly say this is a classifier, AutoGluon will pick it up.\n",
    "predictor = TabularPredictor(label=\"target\") \\\n",
    "    .fit(train_data=df_train, time_limit=120, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b15550-b62b-4a80-857e-12710eee9e73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestGini_BAG_L1   0.985915       0.117629   0.785026                0.117629           0.785026            1       True          4\n",
      "1    NeuralNetFastAI_BAG_L1   0.985915       0.539135  27.118259                0.539135          27.118259            1       True          3\n",
      "2       WeightedEnsemble_L2   0.985915       0.539761  27.383442                0.000626           0.265183            2       True         11\n",
      "3           CatBoost_BAG_L1   0.978873       0.060538   8.553924                0.060538           8.553924            1       True          6\n",
      "4   RandomForestEntr_BAG_L1   0.978873       0.108949   0.726085                0.108949           0.726085            1       True          5\n",
      "5     ExtraTreesEntr_BAG_L1   0.978873       0.112620   0.601538                0.112620           0.601538            1       True          8\n",
      "6     ExtraTreesGini_BAG_L1   0.978873       0.120867   0.719557                0.120867           0.719557            1       True          7\n",
      "7     NeuralNetMXNet_BAG_L1   0.971831       2.963818  47.393598                2.963818          47.393598            1       True         10\n",
      "8            XGBoost_BAG_L1   0.957746       0.134348   8.571076                0.134348           8.571076            1       True          9\n",
      "9     KNeighborsDist_BAG_L1   0.711268       0.010720   0.012010                0.010720           0.012010            1       True          2\n",
      "10    KNeighborsUnif_BAG_L1   0.661972       0.018754   0.030572                0.018754           0.030572            1       True          1\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_NNFastAiTabular', 'WeightedEnsembleModel', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20220110_214459/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetMXNet_BAG_L1': 'StackerEnsembleModel_TabularNeuralNet',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.6619718309859155,\n",
       "  'KNeighborsDist_BAG_L1': 0.7112676056338029,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.9859154929577465,\n",
       "  'RandomForestGini_BAG_L1': 0.9859154929577465,\n",
       "  'RandomForestEntr_BAG_L1': 0.9788732394366197,\n",
       "  'CatBoost_BAG_L1': 0.9788732394366197,\n",
       "  'ExtraTreesGini_BAG_L1': 0.9788732394366197,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.9788732394366197,\n",
       "  'XGBoost_BAG_L1': 0.9577464788732394,\n",
       "  'NeuralNetMXNet_BAG_L1': 0.971830985915493,\n",
       "  'WeightedEnsemble_L2': 0.9859154929577465},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/KNeighborsDist_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'RandomForestGini_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/RandomForestGini_BAG_L1/',\n",
       "  'RandomForestEntr_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/RandomForestEntr_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesGini_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/ExtraTreesGini_BAG_L1/',\n",
       "  'ExtraTreesEntr_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/ExtraTreesEntr_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetMXNet_BAG_L1': 'AutogluonModels/ag-20220110_214459/models/NeuralNetMXNet_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20220110_214459/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.030571937561035156,\n",
       "  'KNeighborsDist_BAG_L1': 0.01201009750366211,\n",
       "  'NeuralNetFastAI_BAG_L1': 27.11825942993164,\n",
       "  'RandomForestGini_BAG_L1': 0.7850260734558105,\n",
       "  'RandomForestEntr_BAG_L1': 0.7260847091674805,\n",
       "  'CatBoost_BAG_L1': 8.553923606872559,\n",
       "  'ExtraTreesGini_BAG_L1': 0.7195568084716797,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.6015379428863525,\n",
       "  'XGBoost_BAG_L1': 8.571075677871704,\n",
       "  'NeuralNetMXNet_BAG_L1': 47.393598318099976,\n",
       "  'WeightedEnsemble_L2': 0.2651829719543457},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.018754243850708008,\n",
       "  'KNeighborsDist_BAG_L1': 0.010719776153564453,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.539135217666626,\n",
       "  'RandomForestGini_BAG_L1': 0.11762881278991699,\n",
       "  'RandomForestEntr_BAG_L1': 0.10894894599914551,\n",
       "  'CatBoost_BAG_L1': 0.06053781509399414,\n",
       "  'ExtraTreesGini_BAG_L1': 0.12086677551269531,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.11262011528015137,\n",
       "  'XGBoost_BAG_L1': 0.13434767723083496,\n",
       "  'NeuralNetMXNet_BAG_L1': 2.963817834854126,\n",
       "  'WeightedEnsemble_L2': 0.0006260871887207031},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetMXNet_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                       model  score_val  pred_time_val   fit_time  \\\n",
       " 0   RandomForestGini_BAG_L1   0.985915       0.117629   0.785026   \n",
       " 1    NeuralNetFastAI_BAG_L1   0.985915       0.539135  27.118259   \n",
       " 2       WeightedEnsemble_L2   0.985915       0.539761  27.383442   \n",
       " 3           CatBoost_BAG_L1   0.978873       0.060538   8.553924   \n",
       " 4   RandomForestEntr_BAG_L1   0.978873       0.108949   0.726085   \n",
       " 5     ExtraTreesEntr_BAG_L1   0.978873       0.112620   0.601538   \n",
       " 6     ExtraTreesGini_BAG_L1   0.978873       0.120867   0.719557   \n",
       " 7     NeuralNetMXNet_BAG_L1   0.971831       2.963818  47.393598   \n",
       " 8            XGBoost_BAG_L1   0.957746       0.134348   8.571076   \n",
       " 9     KNeighborsDist_BAG_L1   0.711268       0.010720   0.012010   \n",
       " 10    KNeighborsUnif_BAG_L1   0.661972       0.018754   0.030572   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.117629           0.785026            1       True   \n",
       " 1                 0.539135          27.118259            1       True   \n",
       " 2                 0.000626           0.265183            2       True   \n",
       " 3                 0.060538           8.553924            1       True   \n",
       " 4                 0.108949           0.726085            1       True   \n",
       " 5                 0.112620           0.601538            1       True   \n",
       " 6                 0.120867           0.719557            1       True   \n",
       " 7                 2.963818          47.393598            1       True   \n",
       " 8                 0.134348           8.571076            1       True   \n",
       " 9                 0.010720           0.012010            1       True   \n",
       " 10                0.018754           0.030572            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0           4  \n",
       " 1           3  \n",
       " 2          11  \n",
       " 3           6  \n",
       " 4           5  \n",
       " 5           8  \n",
       " 6           7  \n",
       " 7          10  \n",
       " 8           9  \n",
       " 9           2  \n",
       " 10          1  }"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373d5630-84b5-4fbb-9b9a-08871ec4fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 1.0\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 1.0,\n",
      "    \"balanced_accuracy\": 1.0,\n",
      "    \"mcc\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614c377-9f5b-4a2a-bc3c-0a049413b6e5",
   "metadata": {},
   "source": [
    "## AutoGluon Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe39b07-53b3-4576-b392-1a1df77b43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36b9530-5bcd-40b4-a1f0-e6ad32bac145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diabetes `data` dataset as a dataframe and name the columns with\n",
    "# `feature_names`\n",
    "dfd = pd.DataFrame(diabetes[\"data\"], columns=diabetes[\"feature_names\"])\n",
    "\n",
    "# Include the target as well\n",
    "dfd[\"target\"] = diabetes[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a9b895-00a5-48b9-951f-e36436255d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0f9d06-9436-4a4e-988d-f0ad00b26e10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220110_214644/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220110_214644/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    353\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (346.0, 25.0, 151.60623, 78.40991)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2687.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['age', 'sex', 'bmi', 'bp', 's1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.83s of the 119.82s of remaining time.\n",
      "\t0.4305\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.73s of the 119.73s of remaining time.\n",
      "\t0.4397\t = Validation score   (r2)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 119.66s of the 119.66s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: image not found\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 119.58s of the 119.58s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: image not found\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 119.53s of the 119.53s of remaining time.\n",
      "\t0.4667\t = Validation score   (r2)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 118.59s of the 118.59s of remaining time.\n",
      "\t0.5228\t = Validation score   (r2)\n",
      "\t2.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 116.02s of the 116.02s of remaining time.\n",
      "\t0.5022\t = Validation score   (r2)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 115.17s of the 115.17s of remaining time.\n",
      "\t0.488\t = Validation score   (r2)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 111.19s of the 111.19s of remaining time.\n",
      "\t0.4456\t = Validation score   (r2)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 106.32s of the 106.32s of remaining time.\n",
      "\t0.4899\t = Validation score   (r2)\n",
      "\t17.24s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 88.33s of the 88.32s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /usr/local/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: image not found\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 88.25s of the 88.25s of remaining time.\n",
      "\t0.5223\t = Validation score   (r2)\n",
      "\t4.9s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 85.81s of the 85.81s of remaining time.\n",
      "\t0.4949\t = Validation score   (r2)\n",
      "\t7.5s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 81.9s of the 81.9s of remaining time.\n",
      "\t0.4447\t = Validation score   (r2)\n",
      "\t8.83s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 76.64s of the 76.63s of remaining time.\n",
      "\t0.5015\t = Validation score   (r2)\n",
      "\t34.89s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 58.29s of the 58.28s of remaining time.\n",
      "\t0.5231\t = Validation score   (r2)\n",
      "\t7.08s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 56.05s of the 56.05s of remaining time.\n",
      "\t0.4981\t = Validation score   (r2)\n",
      "\t11.78s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 51.56s of the 51.55s of remaining time.\n",
      "\t0.4522\t = Validation score   (r2)\n",
      "\t15.06s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 44.57s of the 44.57s of remaining time.\n",
      "\t0.4918\t = Validation score   (r2)\n",
      "\t54.9s\t = Training   runtime\n",
      "\t2.3s\t = Validation runtime\n",
      "Completed 3/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.83s of the 23.37s of remaining time.\n",
      "\t0.5252\t = Validation score   (r2)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 96.97s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220110_214644/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model\n",
    "# parameters? Using the hyperparameters in the requirements, is there\n",
    "# improvement? Remember we use the test dataset to score the model. No need to\n",
    "# explicitly say this is a regression, AutoGluon will pick it up.\n",
    "predictor = TabularPredictor(label=\"target\", eval_metric=\"r2\") \\\n",
    "    .fit(train_data=dfd_train, time_limit=120, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b09621b-9ce7-4889-bcf9-c9b8687438ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L2   0.525215       2.637597  74.078106                0.000580           0.301894            2       True          9\n",
      "1         CatBoost_BAG_L1   0.523150       0.038673   7.081758                0.038673           7.081758            1       True          4\n",
      "2    ExtraTreesMSE_BAG_L1   0.502246       0.119874   0.605108                0.119874           0.605108            1       True          5\n",
      "3  NeuralNetFastAI_BAG_L1   0.498088       0.281615  11.775291                0.281615          11.775291            1       True          6\n",
      "4   NeuralNetMXNet_BAG_L1   0.491805       2.300716  54.902622                2.300716          54.902622            1       True          8\n",
      "5  RandomForestMSE_BAG_L1   0.466743       0.117972   0.720549                0.117972           0.720549            1       True          3\n",
      "6          XGBoost_BAG_L1   0.452164       0.090931  15.061850                0.090931          15.061850            1       True          7\n",
      "7   KNeighborsDist_BAG_L1   0.439701       0.016013   0.016541                0.016013           0.016541            1       True          2\n",
      "8   KNeighborsUnif_BAG_L1   0.430521       0.066601   0.008977                0.066601           0.008977            1       True          1\n",
      "Number of models trained: 9\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_NNFastAiTabular', 'WeightedEnsembleModel', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20220110_214644/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetMXNet_BAG_L1': 'StackerEnsembleModel_TabularNeuralNet',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.43052099899418794,\n",
       "  'KNeighborsDist_BAG_L1': 0.43970122394744415,\n",
       "  'RandomForestMSE_BAG_L1': 0.4667434753086127,\n",
       "  'CatBoost_BAG_L1': 0.5231497544217285,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.502246448213272,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.4980876886527339,\n",
       "  'XGBoost_BAG_L1': 0.4521637200377172,\n",
       "  'NeuralNetMXNet_BAG_L1': 0.4918045287008994,\n",
       "  'WeightedEnsemble_L2': 0.5252154391098123},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/KNeighborsDist_BAG_L1/',\n",
       "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/RandomForestMSE_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/ExtraTreesMSE_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetMXNet_BAG_L1': 'AutogluonModels/ag-20220110_214644/models/NeuralNetMXNet_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20220110_214644/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.008976936340332031,\n",
       "  'KNeighborsDist_BAG_L1': 0.016541242599487305,\n",
       "  'RandomForestMSE_BAG_L1': 0.7205491065979004,\n",
       "  'CatBoost_BAG_L1': 7.08175802230835,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.6051080226898193,\n",
       "  'NeuralNetFastAI_BAG_L1': 11.775290727615356,\n",
       "  'XGBoost_BAG_L1': 15.06185007095337,\n",
       "  'NeuralNetMXNet_BAG_L1': 54.90262198448181,\n",
       "  'WeightedEnsemble_L2': 0.301893949508667},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.06660127639770508,\n",
       "  'KNeighborsDist_BAG_L1': 0.01601266860961914,\n",
       "  'RandomForestMSE_BAG_L1': 0.11797189712524414,\n",
       "  'CatBoost_BAG_L1': 0.03867316246032715,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.1198740005493164,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.2816152572631836,\n",
       "  'XGBoost_BAG_L1': 0.09093141555786133,\n",
       "  'NeuralNetMXNet_BAG_L1': 2.300715684890747,\n",
       "  'WeightedEnsemble_L2': 0.0005800724029541016},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetMXNet_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                     model  score_val  pred_time_val   fit_time  \\\n",
       " 0     WeightedEnsemble_L2   0.525215       2.637597  74.078106   \n",
       " 1         CatBoost_BAG_L1   0.523150       0.038673   7.081758   \n",
       " 2    ExtraTreesMSE_BAG_L1   0.502246       0.119874   0.605108   \n",
       " 3  NeuralNetFastAI_BAG_L1   0.498088       0.281615  11.775291   \n",
       " 4   NeuralNetMXNet_BAG_L1   0.491805       2.300716  54.902622   \n",
       " 5  RandomForestMSE_BAG_L1   0.466743       0.117972   0.720549   \n",
       " 6          XGBoost_BAG_L1   0.452164       0.090931  15.061850   \n",
       " 7   KNeighborsDist_BAG_L1   0.439701       0.016013   0.016541   \n",
       " 8   KNeighborsUnif_BAG_L1   0.430521       0.066601   0.008977   \n",
       " \n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                0.000580           0.301894            2       True   \n",
       " 1                0.038673           7.081758            1       True   \n",
       " 2                0.119874           0.605108            1       True   \n",
       " 3                0.281615          11.775291            1       True   \n",
       " 4                2.300716          54.902622            1       True   \n",
       " 5                0.117972           0.720549            1       True   \n",
       " 6                0.090931          15.061850            1       True   \n",
       " 7                0.016013           0.016541            1       True   \n",
       " 8                0.066601           0.008977            1       True   \n",
       " \n",
       "    fit_order  \n",
       " 0          9  \n",
       " 1          4  \n",
       " 2          5  \n",
       " 3          6  \n",
       " 4          8  \n",
       " 5          3  \n",
       " 6          7  \n",
       " 7          2  \n",
       " 8          1  }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c39401-a8cb-4e6c-aabb-c318f384e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: r2 on test data: 0.32045118569633957\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"r2\": 0.32045118569633957,\n",
      "    \"root_mean_squared_error\": -59.03115052813201,\n",
      "    \"mean_squared_error\": -3484.67673267498,\n",
      "    \"mean_absolute_error\": -44.845230788327335,\n",
      "    \"pearsonr\": 0.5775108744156171,\n",
      "    \"median_absolute_error\": -36.25103759765625\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(dfd_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
